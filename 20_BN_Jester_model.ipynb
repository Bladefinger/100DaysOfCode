{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNjw550MQacT0ZD9jHVsmfT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bladefinger/100DaysOfCode/blob/main/20_BN_Jester_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7wppDnsHsQp"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "tsbx_V3UH8-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "_A4iI5qAIEvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "7L9yKjbQIFJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download toxicmender/20bn-jester -p /content/sample_data/20BnJester --unzip"
      ],
      "metadata": {
        "id": "ORX5_56RIGuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "from imageio import imread"
      ],
      "metadata": {
        "id": "0q2BNuTnIZow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import abc\n",
        "from sys import getsizeof"
      ],
      "metadata": {
        "id": "grDgabITIrQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "cikpCo2-Iukx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.random.set_seed(30)"
      ],
      "metadata": {
        "id": "eIORcpdEMIuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
        "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from keras import optimizers\n",
        "from keras.layers import Dropout"
      ],
      "metadata": {
        "id": "JcWrbiZtIx6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_folder='/content/sample_data/20BnJester'"
      ],
      "metadata": {
        "id": "7qmL0RuVIz55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to plot the training/validation accuracies/losses.\n",
        "\n",
        "def plot(history):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
        "    axes[0].plot(history.history['loss'])   \n",
        "    axes[0].plot(history.history['val_loss'])\n",
        "    axes[0].grid()\n",
        "    axes[0].legend(['loss','val_loss'])\n",
        "    axes[1].plot(history.history['categorical_accuracy'])   \n",
        "    axes[1].plot(history.history['val_categorical_accuracy'])\n",
        "    axes[1].grid()\n",
        "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "wv1aRDDsI6be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelBuilder(metaclass= abc.ABCMeta):\n",
        "    # initialisng the path where project data resides\n",
        "    def initialize_path(self,project_folder):\n",
        "        self.train_doc = np.random.permutation(open(project_folder + '/' + 'Train.csv').readlines())\n",
        "        self.val_doc = np.random.permutation(open(project_folder + '/' + 'Validation.csv').readlines())\n",
        "        self.train_path = project_folder + '/' + 'Train'\n",
        "        self.val_path =  project_folder + '/' + 'Validation'\n",
        "        self.num_train_sequences = len(self.train_doc)\n",
        "        self.num_val_sequences = len(self.val_doc)\n",
        "    # initialising the image properties    \n",
        "    def initialize_image_properties(self,image_height=100,image_width=176):\n",
        "        self.image_height=image_height\n",
        "        self.image_width=image_width\n",
        "        self.channels=3\n",
        "        self.num_classes=37\n",
        "        self.total_frames=37\n",
        "    # initialising the batch size, frames to sample and the no. of epochs\n",
        "    def initialize_hyperparams(self,frames_to_sample=16,batch_size=8,num_epochs=20):\n",
        "        self.frames_to_sample=frames_to_sample\n",
        "        self.batch_size=batch_size\n",
        "        self.num_epochs=num_epochs\n",
        "        \n",
        "    # MOST IMPORTANT PART HERE - The generator function        \n",
        "    def generator(self,source_path, folder_list, augment=False):\n",
        "        img_idx = np.round(np.linspace(0,self.total_frames-1,self.frames_to_sample)).astype(int)\n",
        "        batch_size=self.batch_size\n",
        "        while True:\n",
        "            t = np.random.permutation(folder_list)\n",
        "            num_batches = len(t)//batch_size\n",
        "        \n",
        "            for batch in range(num_batches): \n",
        "                batch_data, batch_labels= self.one_batch_data(source_path,t,batch,batch_size,img_idx,augment)\n",
        "                yield batch_data, batch_labels \n",
        "\n",
        "            remaining_seq=len(t)%batch_size\n",
        "        \n",
        "            if (remaining_seq != 0):\n",
        "                batch_data, batch_labels= self.one_batch_data(source_path,t,num_batches,batch_size,img_idx,augment,remaining_seq)\n",
        "                yield batch_data, batch_labels \n",
        "    \n",
        "    \n",
        "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
        "    \n",
        "        seq_len = remaining_seq if remaining_seq else batch_size\n",
        "    \n",
        "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
        "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
        "    \n",
        "        if (augment): batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
        "\n",
        "        \n",
        "        for folder in range(seq_len): \n",
        "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
        "            for idx,item in enumerate(img_idx):\n",
        "                #performing image reading and resizing\n",
        "                image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                image_resized=resize(image,(self.image_height,self.image_width,3))\n",
        "            \n",
        "                #normalizing the images\n",
        "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
        "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
        "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
        "            \n",
        "                if (augment):\n",
        "                    shifted = cv2.warpAffine(image, \n",
        "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
        "                                            (image.shape[1], image.shape[0]))\n",
        "                    \n",
        "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
        "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
        "                    # cropping the images to have the targeted gestures and remove the noise from the images.\n",
        "                    cropped=shifted[x0:x1,y0:y1,:]\n",
        "                    \n",
        "                    image_resized=resize(cropped,(self.image_height,self.image_width,3))\n",
        "                    \n",
        "                    #shifted = cv2.warpAffine(image_resized, \n",
        "                    #                        np.float32([[1, 0, np.random.randint(-3,3)],[0, 1, np.random.randint(-3,3)]]), \n",
        "                    #                        (image_resized.shape[1], image_resized.shape[0]))\n",
        "            \n",
        "                    batch_data_aug[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
        "                    batch_data_aug[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
        "                    batch_data_aug[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
        "                \n",
        "            \n",
        "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            \n",
        "    \n",
        "        if (augment):\n",
        "            batch_data=np.concatenate([batch_data,batch_data_aug])\n",
        "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
        "\n",
        "        \n",
        "        return(batch_data,batch_labels)\n",
        "    \n",
        "    \n",
        "    def train_model(self, model, augment_data=False):\n",
        "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
        "        val_generator = self.generator(self.val_path, self.val_doc)\n",
        "\n",
        "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "        if not os.path.exists(model_name):\n",
        "            os.mkdir(model_name)\n",
        "        \n",
        "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
        "        \n",
        "        earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
        "        callbacks_list = [checkpoint, LR, earlystop]\n",
        "\n",
        "        if (self.num_train_sequences%self.batch_size) == 0:\n",
        "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
        "        else:\n",
        "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
        "\n",
        "        if (self.num_val_sequences%self.batch_size) == 0:\n",
        "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
        "        else:\n",
        "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
        "    \n",
        "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
        "                            callbacks=callbacks_list, validation_data=val_generator, \n",
        "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
        "        return history\n",
        "\n",
        "        \n",
        "    @abc.abstractmethod\n",
        "    def define_model(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "n47zyJdQI-pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D1(ModelBuilder):\n",
        "    \n",
        "    def define_model(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Dense(64,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = tf.keras.optimizers.SGD()\n",
        "        #optimiser = 'sgd'\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "04nHIvcPJDiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=176)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=8,num_epochs=1)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "conv_3d1_model.summary()"
      ],
      "metadata": {
        "id": "fItHBiRtJFv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "history_model17=conv_3d1.train_model(conv_3d1_model)"
      ],
      "metadata": {
        "id": "j_WqF6YmJHsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/sample_data/20BnJester/Train.csv')\n",
        "test = pd.read_csv('/content/sample_data/20BnJester/Train.csv')\n",
        "validation = pd.read_csv('/content/sample_data/20BnJester/Validation.csv')\n",
        "train.head()\n",
        "test.head()\n",
        "validation.head()"
      ],
      "metadata": {
        "id": "ZiQ56k4VoBUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['frames', 'shape', 'format'], axis=1, inplace=True)\n",
        "test.drop(['frames', 'shape', 'format'], axis=1, inplace=True)\n",
        "validation.drop(['frames', 'shape', 'format'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "n0OAoD1TobQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train.head()\n",
        "#test.head()\n",
        "validation.head()"
      ],
      "metadata": {
        "id": "_STpD65MpOjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv('Train.csv')\n",
        "test.to_csv('Test.csv')\n",
        "validation.to_csv('Validation.csv')"
      ],
      "metadata": {
        "id": "Kfu1iOP3p_1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PkQQC053q8bs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}